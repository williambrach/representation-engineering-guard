{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a619437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gqr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from repe import repe_pipeline_registry\n",
    "\n",
    "repe_pipeline_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60e842",
   "metadata": {},
   "source": [
    "## Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044819fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, dtype=torch.float16, device_map=\"balanced_low_0\"\n",
    ").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=False)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = (\n",
    "    tokenizer.unk_token if tokenizer.pad_token is None else tokenizer.pad_token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05478741",
   "metadata": {},
   "source": [
    "## Prompt template\n",
    "\n",
    "- each model has its own prompt template \n",
    "- llama3.1, prompt template - https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a6846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{query}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7541c637",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1716ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gqr dataset\n",
    "train_dataset, test_dataset = gqr.load_train_dataset()\n",
    "\n",
    "\n",
    "# apply prompt template to the dataset\n",
    "train_dataset[\"text_template\"] = train_dataset[\"text\"].apply(\n",
    "    lambda x: template.format(query=x)\n",
    ")\n",
    "test_dataset[\"text_template\"] = test_dataset[\"text\"].apply(\n",
    "    lambda x: template.format(query=x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 128\n",
    "\n",
    "# Select N_SAMPLES from dataset with label 1 and N_SAMPLES with label != 1\n",
    "train_positive = (\n",
    "    train_dataset[train_dataset[\"label\"] == 1]\n",
    "    .sample(n=N_SAMPLES, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "train_negative = (\n",
    "    train_dataset[train_dataset[\"label\"] != 1]\n",
    "    .sample(n=N_SAMPLES, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(len(train_positive)):\n",
    "    # Append the positive and negative example sentences\n",
    "    train_data.append(train_positive.loc[i, \"text_template\"])\n",
    "    train_data.append(train_negative.loc[i, \"text_template\"])\n",
    "\n",
    "    # Append the corresponding labels for the pair\n",
    "    train_labels.append([1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_data).shape, np.array(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_token = -1 # Use the last token for representation\n",
    "hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1)) # what hidden layers to use for representation\n",
    "n_difference = 1 # use the difference between the two representations in a pair\n",
    "direction_method = \"pca\"\n",
    "rep_reading_pipeline = pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "direction_finder_kwargs = {\"n_components\": 3}\n",
    "\n",
    "# Set the padding token string\n",
    "if rep_reading_pipeline.tokenizer.pad_token is None:\n",
    "    rep_reading_pipeline.tokenizer.pad_token = rep_reading_pipeline.tokenizer.eos_token\n",
    "\n",
    "# Set the padding token ID\n",
    "rep_reading_pipeline.tokenizer.pad_token_id = (\n",
    "    rep_reading_pipeline.tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "rep_reader = rep_reading_pipeline.get_directions(\n",
    "    train_data,\n",
    "    rep_token=rep_token,\n",
    "    hidden_layers=hidden_layers,\n",
    "    n_difference=n_difference,\n",
    "    train_labels=train_labels,\n",
    "    direction_method=direction_method,\n",
    "    direction_finder_kwargs=direction_finder_kwargs,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color map for your labels.\n",
    "# Assign a specific color for each label (e.g., 0 and 1).\n",
    "color_map = {0: \"green\", 1: \"red\", 2: \"green\", 3: \"blue\"}\n",
    "\n",
    "\n",
    "for q in range(10):\n",
    "    new_query = [test_dataset[\"text_template\"].values[q]]\n",
    "    current_label = test_dataset[\"label\"].values[q]\n",
    "\n",
    "    # Use the rep_reading_pipeline to get the scores for the new query\n",
    "    scores = rep_reading_pipeline(\n",
    "        new_query,\n",
    "        rep_reader=rep_reader,\n",
    "        rep_token=rep_token,\n",
    "        hidden_layers=hidden_layers,\n",
    "        component_index=0,\n",
    "    )\n",
    "\n",
    "    # The 'scores' variable will be a dictionary containing the scores for each layer.\n",
    "    # The key is the layer, and the value is a numpy array.\n",
    "    # We need to extract the score for each layer and convert it to a float.\n",
    "    # We also need to get the color for the current label from the colormap.\n",
    "    layer_scores = scores[0]\n",
    "\n",
    "    layer_scores = [float(layer_scores[s][0]) for s in layer_scores]\n",
    "    color_for_plot = color_map[current_label]\n",
    "\n",
    "    plt.plot(\n",
    "        range(len(layer_scores)),\n",
    "        layer_scores,\n",
    "        color=color_for_plot,\n",
    "        label=f\"Label: {current_label}\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "# now do harassment / offensive dataset\n",
    "\n",
    "negative = [\n",
    "    \"this is harassment\",\n",
    "    \"I hate you\",\n",
    "    \"you are so annoying\",\n",
    "    \"this is offensive\",\n",
    "    \"I can't stand you\",\n",
    "    \"I will kill you!\",\n",
    "]\n",
    "\n",
    "for q in negative:\n",
    "    new_query = [template.format(query=q)]\n",
    "    current_label = 3\n",
    "\n",
    "    # Use the rep_reading_pipeline to get the scores for the new query\n",
    "    scores = rep_reading_pipeline(\n",
    "        new_query,\n",
    "        rep_reader=rep_reader,\n",
    "        rep_token=rep_token,\n",
    "        hidden_layers=hidden_layers,\n",
    "        component_index=2,\n",
    "    )\n",
    "\n",
    "    layer_scores = scores[0]\n",
    "\n",
    "    layer_scores = [float(layer_scores[s][0]) for s in layer_scores]\n",
    "    color_for_plot = color_map[current_label]\n",
    "\n",
    "    plt.plot(\n",
    "        range(len(layer_scores)),\n",
    "        layer_scores,\n",
    "        color=color_for_plot,\n",
    "        label=f\"Label: {current_label}\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bbe84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representation-engineering-guard (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
